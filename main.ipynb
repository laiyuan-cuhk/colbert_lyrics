{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"zdXDwHEfRW2f"},"outputs":[],"source":["'''\n","1. Get api key: secret(left side bar top 4) -> Gemni API keys (unavailable in HK, use vpn)\n","    as env: GOOGLE_API_KEY\n","2.\n","'''\n","!curl https://ipinfo.io/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w3a6tSo1Msr8"},"outputs":[],"source":["%%capture\n","%%bash\n","#install packages\n","\n","#hugging face\n","pip install -U datasets\n","\n","\n","#colbert: tpu/gpu\n","pip install gitpython\n","pip install faiss-cpu\n","\n","pip install pandas gdown shortuuid"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LigpmPka2N2w"},"outputs":[],"source":["%%capture\n","\n","'''\n","setup colbert / plaidrepro\n","'''\n","\n","import os\n","original_cwd = os.getcwd()\n","os.chdir('/tmp')\n","\n","!rm -rf ./ColBERT ./plaidrepro\n","!git -C ColBERT/ pull || git clone https://github.com/stanford-futuredata/ColBERT.git\n","\n","#!mv ./plaidrepro ./ColBERT\n","import sys; sys.path.insert(0, '/tmp/ColBERT/')\n","\n","try: # When on google Colab, let's install all dependencies with pip.\n","    import google.colab\n","    !pip install -U pip\n","    !pip install -e ColBERT/['faiss-gpu','torch']\n","except Exception:\n","  import sys; sys.path.insert(0, 'ColBERT/')\n","  try:\n","    from colbert import Indexer, Searcher\n","  except Exception:\n","    print(\"If you're running outside Colab, please make sure you install ColBERT in conda following the instructions in our README. You can also install (as above) with pip but it may install slower or less stable faiss or torch dependencies. Conda is recommended.\")\n","    assert False\n","\n","os.chdir(original_cwd)\n","print(f\"Changed back to: {os.getcwd()}\")\n","\n","!pip install bitarray datasets gitpython ninja scipy spacy tqdm transformers ujson flask python-dotenv"]},{"cell_type":"markdown","metadata":{"id":"wMCYgI0L2Nw2"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LdjouDApVc27"},"outputs":[],"source":["'''\n","load benchmark data\n","'''\n","'''\n","from datasets import load_dataset\n","mrag_bench = load_dataset(\"brunokreiner/genius-lyrics\", split='train')\n","display(mrag_bench)\n","\n","display(mrag_bench[0]['id'])\n","display(mrag_bench[0]['lyrics'])\n","'''"]},{"cell_type":"code","source":["%%bash\n","wget -qq https://github.com/gaussic/Chinese-Lyric-Corpus/raw/refs/heads/master/Chinese_Lyrics.zip\n","unzip Chinese_Lyrics.zip\n","rm -f Chinese_Lyrics.zip"],"metadata":{"id":"K803cYPKcVle"},"execution_count":null,"outputs":[]},{"source":["import os\n","\n","def find_and_read_txt_files(folder_path):\n","    \"\"\"\n","    Recursively finds all .txt files in a folder, sorts them by filename,\n","    and reads their content into one array and their filenames into another.\n","\n","    Args:\n","        folder_path: The path to the folder to search.\n","\n","    Returns:\n","        A tuple containing two lists:\n","        - A list of file contents (strings).\n","        - A list of filenames (strings).\n","    \"\"\"\n","    txt_files = []\n","    for root, _, files in os.walk(folder_path):\n","        for file in files:\n","            if file.endswith(\".txt\"):\n","                txt_files.append(os.path.join(root, file))\n","\n","    txt_files.sort()\n","\n","    file_contents = []\n","    filenames = []\n","    for txt_file in txt_files:\n","        with open(txt_file, 'r', encoding='utf-8') as f:\n","            file_contents.append(f.read())\n","        filenames.append(os.path.basename(txt_file))\n","\n","    return file_contents, filenames\n","\n","# Example usage:\n","folder_to_search = './Chinese_Lyrics'\n","file_contents, filenames = find_and_read_txt_files(folder_to_search)\n","\n","\n","\n","# To see the contents and filenames, you can print them:\n","#print(\"File contents:\", file_contents)\n","#print(\"Filenames:\", filenames)\n","\n","# You can access individual elements like this:\n","print(\"First file content:\", file_contents[0])\n","print(\"First filename:\", filenames[0])"],"cell_type":"code","metadata":{"id":"UnFCeeSye0i5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#----------------------------------------------------------------------------------"],"metadata":{"id":"ZFqVQe2JeVVZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JbVIMnojdjG4"},"outputs":[],"source":["%%bash\n","#Download the pre-trained ColBERTv2 checkpoint\n","\n","cd /tmp\n","\n","rm -rf colbertv\n","mkdir -p colbertv\n","cd colbertv\n","#wget -qq https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz -O colbertv2.0.tar.gz\n","wget -qq -O- https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz | tar xvz\n"]},{"cell_type":"code","source":["!rm -rf ./experiments"],"metadata":{"id":"kpYVf1OLOvIK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fYe02JS_yH9t"},"outputs":[],"source":["'''\n","step-1b: RAG system: Plaid\n","'''\n","\n","class RAG():\n","  '''\n","    root_dir: for Colbertv working dir\n","    data_path: for storing input data array, which is missing from Colbertv\n","  '''\n","  def __init__(self, root_dir='./experiments', storage_path='./rag_data.pt'):\n","    import os\n","\n","    self._root_dir = root_dir\n","    self._storage_path = storage_path\n","\n","    if os.path.exists(self._storage_path):\n","        print(f\"Loading data from {self._storage_path}\")\n","        self._load_storage()\n","    else:\n","        print(f\"Data file {self._storage_path} not found. Starting with empty data.\")\n","        self._storage = {\n","            #image descriptions\n","            'data': [],\n","            #filenames\n","            'annotation': []\n","        }\n","\n","  def _save_storage(self):\n","    import json\n","    with open(self._storage_path, 'w') as f:\n","      json.dump(self._storage, f, indent=4)\n","\n","  def _load_storage(self):\n","    import json\n","    with open(self._storage_path, 'r') as f:\n","      self._storage = json.load(f)\n","\n","  '''\n","    Warning:\n","      data list should be at least 100 to make it work, otherwise it stucks\n","  '''\n","  def index(self, data: list[str], annotation: list[str], kmeans_niters=4,\n","    checkpoint_dir=\"./colbertv/colbertv2.0\"\n","  ):\n","    from colbert.infra import Run, RunConfig, ColBERTConfig\n","    from colbert.data import Queries, Collection\n","    from colbert import Indexer, Searcher\n","\n","    with Run().context(RunConfig(nranks=1, experiment=\"msmarco\")):\n","        config = ColBERTConfig(\n","            nbits=2,\n","            root=self._root_dir,\n","            kmeans_niters=kmeans_niters,\n","            avoid_fork_if_possible=True\n","        )\n","        indexer = Indexer(checkpoint=checkpoint_dir, config=config)\n","        indexer.index(name=\"msmarco.nbits.2\", collection=data, overwrite=True)\n","\n","    self._storage['data'] = data\n","    self._storage['annotation'] = annotation\n","    self._save_storage()\n","\n","    print('overwritten storage file!')\n","\n","  def query(self, query: str, top_k=5):\n","    from colbert.infra import Run, RunConfig, ColBERTConfig\n","    from colbert.data import Queries, Collection\n","    from colbert import Indexer, Searcher\n","\n","    with Run().context(RunConfig(nranks=1, experiment=\"msmarco\")):\n","      config = ColBERTConfig(\n","          root=self._root_dir,\n","      )\n","      searcher = Searcher(index=\"msmarco.nbits.2\", config=config)\n","      ranking = searcher.search(query, k=top_k)\n","\n","    return {\n","      'index': ranking[0],\n","      'data': [ self._storage['data'][passage_id] for passage_id in ranking[0] ],\n","      'annotation': [ self._storage['annotation'][passage_id] for passage_id in ranking[0] ]\n","    }\n","\n","#---------------------------[Example usage]----------------------------------\n","songs_name = file_contents\n","songs_text = filenames\n","\n","print('--------------------------use new rag------------------------------------')\n","\n","!rm -f ./rag_data.json\n","\n","rag = RAG(\n","  storage_path='./rag_data.json'\n",")\n","\n","query='Who has 11 cats?'\n","\n","rag.index(data=songs_text, annotation=songs_name,\n","  checkpoint_dir='/tmp/colbertv/colbertv2.0'\n",")\n","\n","answer = rag.query(query=query)\n","print(f'query: {query}')\n","print(f'top-k answer: {answer}')\n","print(f'best answer: {answer[\"data\"][0]} @{answer[\"annotation\"][0]}')"]},{"cell_type":"code","source":["query='Lost of sleep. Secret crush'\n","\n","rag = RAG(\n","  storage_path='./rag_data.json'\n",")\n","\n","answer = rag.query(query=query)\n","\n","print(f'query: {query}')\n","#print(f'top-k answer: {answer}')\n","for data,annotation in zip(answer[\"data\"], answer[\"annotation\"]):\n","  print(f'<{annotation}>\\n{data}\\n\\n')"],"metadata":{"id":"9ir1BIZuubnA"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vmZupWZvmdzW"},"outputs":[],"source":["%%bash\n","rm -f experiments.7z\n","mv ./rag_data.json ./experiments/\n","7z a experiments.7z ./experiments\n","rm -rf ./experiments"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPyJUujT5FtvZkg2yAD5Ov0"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}